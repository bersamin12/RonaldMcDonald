1
00:00:00,040 --> 00:00:03,120
it's official the AI hype train just

2
00:00:01,880 --> 00:00:06,080
went on life support with the

3
00:00:03,120 --> 00:00:08,000
underwhelming release of GPT 4.5

4
00:00:06,080 --> 00:00:10,240
yesterday open AI unveiled the most

5
00:00:08,000 --> 00:00:12,280
expensive AI model ever produced yet it

6
00:00:10,240 --> 00:00:14,719
fails to crush any benchmarks win any

7
00:00:12,280 --> 00:00:16,720
awards or offer any novel capabilities

8
00:00:14,719 --> 00:00:18,720
whatsoever its only real selling point

9
00:00:16,720 --> 00:00:20,800
is Vibes and is supposed to chat in a

10
00:00:18,720 --> 00:00:22,760
more natural human-like way don't get me

11
00:00:20,800 --> 00:00:24,840
wrong it's a good model but not good

12
00:00:22,760 --> 00:00:26,519
enough to feed the AI hype monster and

13
00:00:24,840 --> 00:00:28,039
it looks increasingly likely that we're

14
00:00:26,519 --> 00:00:30,039
not headed into a technological

15
00:00:28,039 --> 00:00:31,759
singularity but rather a sigmoid of

16
00:00:30,039 --> 00:00:33,280
sorrow the Sam ultman couldn't even be

17
00:00:31,759 --> 00:00:34,719
bothered to leave his newborn kid in the

18
00:00:33,280 --> 00:00:36,360
hospital to show up to the product

19
00:00:34,719 --> 00:00:38,320
launch and instead send in a bunch of

20
00:00:36,360 --> 00:00:40,079
interns to demo it and that's crazy

21
00:00:38,320 --> 00:00:42,280
because we're talking about Orion here

22
00:00:40,079 --> 00:00:44,079
in 2023 Tech leaders signed a petition

23
00:00:42,280 --> 00:00:45,600
to stop training big models like this

24
00:00:44,079 --> 00:00:47,000
mman himself begged the government to

25
00:00:45,600 --> 00:00:49,239
regulate it and the only thing more

26
00:00:47,000 --> 00:00:51,199
disappointing than GPT 4.5 is the

27
00:00:49,239 --> 00:00:52,800
release of the Epstein files in today's

28
00:00:51,199 --> 00:00:54,800
video we'll find out if we just reach

29
00:00:52,800 --> 00:00:56,920
the limits of pre-training in generative

30
00:00:54,800 --> 00:00:59,519
pre-trained Transformers it is February

31
00:00:56,920 --> 00:01:00,920
28th 2025 and you're watching the code

32
00:00:59,519 --> 00:01:03,199
report I didn't want to make another

33
00:01:00,920 --> 00:01:04,960
crappy AI video today but the bat signal

34
00:01:03,199 --> 00:01:07,000
was triggered anytime an official video

35
00:01:04,960 --> 00:01:08,400
gets ratioed like this I have no choice

36
00:01:07,000 --> 00:01:09,680
but to make a video before you

37
00:01:08,400 --> 00:01:11,439
unsubscribe though I've got an

38
00:01:09,680 --> 00:01:13,759
interesting postgress video on the way

39
00:01:11,439 --> 00:01:15,439
the first thing to know about GPT 4.5 is

40
00:01:13,759 --> 00:01:17,640
that it's extremely expensive if you

41
00:01:15,439 --> 00:01:20,520
thought Claude was expensive at $15 per

42
00:01:17,640 --> 00:01:23,320
million tokens GPT 4.5 is five times

43
00:01:20,520 --> 00:01:25,320
more expensive at $75 per million output

44
00:01:23,320 --> 00:01:28,000
tokens actually no correction that's

45
00:01:25,320 --> 00:01:29,920
input tokens it's $150 per million

46
00:01:28,000 --> 00:01:31,240
output tokens and to chat with it it's

47
00:01:29,920 --> 00:01:33,799
it's currently only available to the

48
00:01:31,240 --> 00:01:35,759
$200 per month Pro users I tried it out

49
00:01:33,799 --> 00:01:37,680
myself and it does seem to emit Chill

50
00:01:35,759 --> 00:01:39,680
Vibes but the problem is that's highly

51
00:01:37,680 --> 00:01:42,000
subjective however in the launch open

52
00:01:39,680 --> 00:01:43,360
aai talked about a new Vibes Benchmark

53
00:01:42,000 --> 00:01:45,119
that's supposed to measure creative

54
00:01:43,360 --> 00:01:47,159
thinking the best way to get a f for the

55
00:01:45,119 --> 00:01:48,360
model is to talk to it so let's jump

56
00:01:47,159 --> 00:01:50,399
into a demo a lot of people on the

57
00:01:48,360 --> 00:01:52,000
internet criticize this presentation but

58
00:01:50,399 --> 00:01:53,880
as an introvert myself I think they did

59
00:01:52,000 --> 00:01:55,960
a great job in addition it apparently

60
00:01:53,880 --> 00:01:57,479
has a far lower hallucination rate but

61
00:01:55,960 --> 00:01:58,920
what I found is that it still makes a

62
00:01:57,479 --> 00:02:00,960
lot of silly mistakes it's not

63
00:01:58,920 --> 00:02:03,520
self-aware and has has no idea what gbt

64
00:02:00,960 --> 00:02:06,159
4.5 even is and says its training cut

65
00:02:03,520 --> 00:02:08,560
off is October 2023 it was however able

66
00:02:06,159 --> 00:02:10,360
to tell me how many RS are in Strawberry

67
00:02:08,560 --> 00:02:11,920
that felt like a huge leap forward but I

68
00:02:10,360 --> 00:02:14,200
quickly became disappointed when it gave

69
00:02:11,920 --> 00:02:15,480
me the wrong number of L's in laap paloa

70
00:02:14,200 --> 00:02:17,120
now when it comes to programming and

71
00:02:15,480 --> 00:02:18,440
science I didn't even try because we

72
00:02:17,120 --> 00:02:20,000
already know it's not going to perform

73
00:02:18,440 --> 00:02:22,280
as well as the deep thinking models like

74
00:02:20,000 --> 00:02:24,200
03 then to make matters worse on the AER

75
00:02:22,280 --> 00:02:26,160
polyglot coding Benchmark it's not only

76
00:02:24,200 --> 00:02:28,040
worse at programming than deep seek but

77
00:02:26,160 --> 00:02:29,640
also hundreds of times more expensive

78
00:02:28,040 --> 00:02:31,720
now if you're an Elon Musk hater you'll

79
00:02:29,640 --> 00:02:33,879
want take a bong rip of copium right now

80
00:02:31,720 --> 00:02:35,879
because currently xai's Gro is the best

81
00:02:33,879 --> 00:02:37,480
model in the world that's not my opinion

82
00:02:35,879 --> 00:02:39,840
it's the opinion of the betting Market

83
00:02:37,480 --> 00:02:41,159
although by the end of 2025 open AI is

84
00:02:39,840 --> 00:02:43,080
still the favorite to have the best

85
00:02:41,159 --> 00:02:44,920
model but its odds are on the decline

86
00:02:43,080 --> 00:02:46,239
that's problematic for open AI though

87
00:02:44,920 --> 00:02:47,720
because they're raising billions and

88
00:02:46,239 --> 00:02:49,599
billions of dollars as they transition

89
00:02:47,720 --> 00:02:51,720
to for-profit and will need to maintain

90
00:02:49,599 --> 00:02:53,480
a massive valuation Alman says there is

91
00:02:51,720 --> 00:02:55,239
no wall and believes they can scale

92
00:02:53,480 --> 00:02:56,640
these models almost infinitely that's

93
00:02:55,239 --> 00:02:58,400
assuming he gets trillions of dollars

94
00:02:56,640 --> 00:03:00,120
from soft Bank in the Saudis to build

95
00:02:58,400 --> 00:03:01,959
these data centers my theory as an

96
00:03:00,120 --> 00:03:03,760
unqualified ship poster is that they

97
00:03:01,959 --> 00:03:05,440
failed to train GPT 5 with any

98
00:03:03,760 --> 00:03:07,200
significant Improvement despite scaling

99
00:03:05,440 --> 00:03:09,280
up the number of parameters in compute

100
00:03:07,200 --> 00:03:10,720
GPT 4.5 is the biggest model they've

101
00:03:09,280 --> 00:03:13,159
ever created and now they're lowering

102
00:03:10,720 --> 00:03:15,000
the bar for gbt 5 which ultman described

103
00:03:13,159 --> 00:03:16,360
a few weeks ago being more like a router

104
00:03:15,000 --> 00:03:17,959
that automatically chooses the best

105
00:03:16,360 --> 00:03:19,400
model based on your prompt and that's

106
00:03:17,959 --> 00:03:21,159
highly disappointing because I was

107
00:03:19,400 --> 00:03:23,080
expecting to be a post-apocalyptic

108
00:03:21,159 --> 00:03:24,799
warlord by now the battling robots and

109
00:03:23,080 --> 00:03:26,440
barbecuing rats over burning garbage

110
00:03:24,799 --> 00:03:28,200
cans for dinner but instead I live in

111
00:03:26,440 --> 00:03:30,000
this dystopia where artificial super

112
00:03:28,200 --> 00:03:31,599
intelligence never comes and nothing

113
00:03:30,000 --> 00:03:33,319
ever happens but if you're a computer

114
00:03:31,599 --> 00:03:35,439
science student the plateau is great

115
00:03:33,319 --> 00:03:37,040
news AI coding tools are incredible but

116
00:03:35,439 --> 00:03:38,519
they're most useful to real human

117
00:03:37,040 --> 00:03:40,040
programmers who know what they're doing

118
00:03:38,519 --> 00:03:41,439
and I don't see that changing anytime

119
00:03:40,040 --> 00:03:43,040
soon and you can start getting really

120
00:03:41,439 --> 00:03:45,040
good at programming for free thanks to

121
00:03:43,040 --> 00:03:47,000
this video sponsor brilliant their

122
00:03:45,040 --> 00:03:49,439
platform provides interactive Hands-On

123
00:03:47,000 --> 00:03:51,319
lessons that demystify the complexity of

124
00:03:49,439 --> 00:03:53,159
deep learning with just a few minutes of

125
00:03:51,319 --> 00:03:55,200
effort each day you can understand the

126
00:03:53,159 --> 00:03:57,480
math and computer science behind this

127
00:03:55,200 --> 00:03:59,239
seemingly magic technology I'd recommend

128
00:03:57,480 --> 00:04:01,040
starting with python then check out

129
00:03:59,239 --> 00:04:02,680
their full how large language models

130
00:04:01,040 --> 00:04:04,640
work course if you really want to look

131
00:04:02,680 --> 00:04:06,200
under the hood of chat gbt try

132
00:04:04,640 --> 00:04:08,120
everything brilliant has to offer for

133
00:04:06,200 --> 00:04:11,079
free for 30 days by going to

134
00:04:08,120 --> 00:04:12,720
brilliant.org fireship or use the QR

135
00:04:11,079 --> 00:04:14,519
code on screen this has been the code

136
00:04:12,720 --> 00:04:18,120
report thanks for watching and I will

137
00:04:14,519 --> 00:04:18,120
see you in the next one